{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the zomato.csv dataset\n",
    "df=pd.read_csv('EDA_FE.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>BILL_AMT_SEPT</th>\n",
       "      <th>BILL_AMT_AUG</th>\n",
       "      <th>BILL_AMT_JUL</th>\n",
       "      <th>BILL_AMT_JUN</th>\n",
       "      <th>BILL_AMT_MAY</th>\n",
       "      <th>BILL_AMT_APR</th>\n",
       "      <th>PAY_AMT_SEPT</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_APR_-1</th>\n",
       "      <th>PAY_APR_0</th>\n",
       "      <th>PAY_APR_2</th>\n",
       "      <th>PAY_APR_3</th>\n",
       "      <th>PAY_APR_4</th>\n",
       "      <th>PAY_APR_5</th>\n",
       "      <th>PAY_APR_6</th>\n",
       "      <th>PAY_APR_7</th>\n",
       "      <th>PAY_APR_8</th>\n",
       "      <th>IsDefaulter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>3102.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>1725.0</td>\n",
       "      <td>2682.0</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>14027.0</td>\n",
       "      <td>13559.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>46990.0</td>\n",
       "      <td>48233.0</td>\n",
       "      <td>49291.0</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>8617.0</td>\n",
       "      <td>5670.0</td>\n",
       "      <td>35835.0</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  AGE  BILL_AMT_SEPT  BILL_AMT_AUG  BILL_AMT_JUL  \\\n",
       "0    20000.0    0   24         3913.0        3102.0         689.0   \n",
       "1   120000.0    0   26         2682.0        1725.0        2682.0   \n",
       "2    90000.0    0   34        29239.0       14027.0       13559.0   \n",
       "3    50000.0    0   37        46990.0       48233.0       49291.0   \n",
       "4    50000.0    1   57         8617.0        5670.0       35835.0   \n",
       "\n",
       "   BILL_AMT_JUN  BILL_AMT_MAY  BILL_AMT_APR  PAY_AMT_SEPT  ...  PAY_APR_-1  \\\n",
       "0           0.0           0.0           0.0           0.0  ...           0   \n",
       "1        3272.0        3455.0        3261.0           0.0  ...           0   \n",
       "2       14331.0       14948.0       15549.0        1518.0  ...           0   \n",
       "3       28314.0       28959.0       29547.0        2000.0  ...           0   \n",
       "4       20940.0       19146.0       19131.0        2000.0  ...           0   \n",
       "\n",
       "   PAY_APR_0  PAY_APR_2  PAY_APR_3  PAY_APR_4  PAY_APR_5  PAY_APR_6  \\\n",
       "0          0          0          0          0          0          0   \n",
       "1          0          1          0          0          0          0   \n",
       "2          1          0          0          0          0          0   \n",
       "3          1          0          0          0          0          0   \n",
       "4          1          0          0          0          0          0   \n",
       "\n",
       "   PAY_APR_7  PAY_APR_8  IsDefaulter  \n",
       "0          0          0            1  \n",
       "1          0          0            1  \n",
       "2          0          0            0  \n",
       "3          0          0            0  \n",
       "4          0          0            0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First five rows of dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46728, 79)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LIMIT_BAL', 'SEX', 'AGE', 'BILL_AMT_SEPT', 'BILL_AMT_AUG',\n",
       "       'BILL_AMT_JUL', 'BILL_AMT_JUN', 'BILL_AMT_MAY', 'BILL_AMT_APR',\n",
       "       'PAY_AMT_SEPT', 'PAY_AMT_AUG', 'PAY_AMT_JUL', 'PAY_AMT_JUN',\n",
       "       'PAY_AMT_MAY', 'PAY_AMT_APR', 'EDUCATION_Graduate School',\n",
       "       'EDUCATION_High School', 'EDUCATION_University', 'MARRIAGE_Married',\n",
       "       'MARRIAGE_Single', 'PAY_SEPT_-1', 'PAY_SEPT_0', 'PAY_SEPT_1',\n",
       "       'PAY_SEPT_2', 'PAY_SEPT_3', 'PAY_SEPT_4', 'PAY_SEPT_5', 'PAY_SEPT_6',\n",
       "       'PAY_SEPT_7', 'PAY_SEPT_8', 'PAY_AUG_-1', 'PAY_AUG_0', 'PAY_AUG_1',\n",
       "       'PAY_AUG_2', 'PAY_AUG_3', 'PAY_AUG_4', 'PAY_AUG_5', 'PAY_AUG_6',\n",
       "       'PAY_AUG_7', 'PAY_AUG_8', 'PAY_JUL_-1', 'PAY_JUL_0', 'PAY_JUL_1',\n",
       "       'PAY_JUL_2', 'PAY_JUL_3', 'PAY_JUL_4', 'PAY_JUL_5', 'PAY_JUL_6',\n",
       "       'PAY_JUL_7', 'PAY_JUL_8', 'PAY_JUN_-1', 'PAY_JUN_0', 'PAY_JUN_1',\n",
       "       'PAY_JUN_2', 'PAY_JUN_3', 'PAY_JUN_4', 'PAY_JUN_5', 'PAY_JUN_6',\n",
       "       'PAY_JUN_7', 'PAY_JUN_8', 'PAY_MAY_-1', 'PAY_MAY_0', 'PAY_MAY_2',\n",
       "       'PAY_MAY_3', 'PAY_MAY_4', 'PAY_MAY_5', 'PAY_MAY_6', 'PAY_MAY_7',\n",
       "       'PAY_MAY_8', 'PAY_APR_-1', 'PAY_APR_0', 'PAY_APR_2', 'PAY_APR_3',\n",
       "       'PAY_APR_4', 'PAY_APR_5', 'PAY_APR_6', 'PAY_APR_7', 'PAY_APR_8',\n",
       "       'IsDefaulter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Columns = ['LIMIT_BAL', 'SEX', 'AGE', 'BILL_AMT_SEPT', 'BILL_AMT_AUG',\n",
    "       'BILL_AMT_JUL', 'BILL_AMT_JUN', 'BILL_AMT_MAY', 'BILL_AMT_APR',\n",
    "       'PAY_AMT_SEPT', 'PAY_AMT_AUG', 'PAY_AMT_JUL', 'PAY_AMT_JUN',\n",
    "       'PAY_AMT_MAY', 'PAY_AMT_APR', 'EDUCATION_Graduate School',\n",
    "       'EDUCATION_High School', 'EDUCATION_University', 'MARRIAGE_Married',\n",
    "       'MARRIAGE_Single', 'PAY_SEPT_-1', 'PAY_SEPT_0', 'PAY_SEPT_1',\n",
    "       'PAY_SEPT_2', 'PAY_SEPT_3', 'PAY_SEPT_4', 'PAY_SEPT_5', 'PAY_SEPT_6',\n",
    "       'PAY_SEPT_7', 'PAY_SEPT_8', 'PAY_AUG_-1', 'PAY_AUG_0', 'PAY_AUG_1',\n",
    "       'PAY_AUG_2', 'PAY_AUG_3', 'PAY_AUG_4', 'PAY_AUG_5', 'PAY_AUG_6',\n",
    "       'PAY_AUG_7', 'PAY_AUG_8', 'PAY_JUL_-1', 'PAY_JUL_0', 'PAY_JUL_1',\n",
    "       'PAY_JUL_2', 'PAY_JUL_3', 'PAY_JUL_4', 'PAY_JUL_5', 'PAY_JUL_6',\n",
    "       'PAY_JUL_7', 'PAY_JUL_8', 'PAY_JUN_-1', 'PAY_JUN_0', 'PAY_JUN_1',\n",
    "       'PAY_JUN_2', 'PAY_JUN_3', 'PAY_JUN_4', 'PAY_JUN_5', 'PAY_JUN_6',\n",
    "       'PAY_JUN_7', 'PAY_JUN_8', 'PAY_MAY_-1', 'PAY_MAY_0', 'PAY_MAY_2',\n",
    "       'PAY_MAY_3', 'PAY_MAY_4', 'PAY_MAY_5', 'PAY_MAY_6', 'PAY_MAY_7',\n",
    "       'PAY_MAY_8', 'PAY_APR_-1', 'PAY_APR_0', 'PAY_APR_2', 'PAY_APR_3',\n",
    "       'PAY_APR_4', 'PAY_APR_5', 'PAY_APR_6', 'PAY_APR_7', 'PAY_APR_8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['IsDefaulter'],axis=1)\n",
    "y = df['IsDefaulter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Numerical Pipeline with Outlier Handling\n",
    "Scaler_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer([\n",
    "    ('Scaler_pipeline', Scaler_pipeline,Columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "#importing XG Boosting Classifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63660258,  1.45434672, -0.27585214, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.98762923, -0.68759395,  0.29143175, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.82858487, -0.68759395,  0.06451819, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       ...,\n",
       "       [ 0.84138082,  1.45434672,  0.17797497, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.82858487, -0.68759395, -1.52387669, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.59001835, -0.68759395, -0.38930892, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.20520341, -0.68759395, -0.27585214, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [ 0.28472559, -0.68759395,  1.42599952, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.11288529, -0.68759395,  0.40488852, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       ...,\n",
       "       [-0.59001835, -0.68759395, -1.52387669, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [ 0.68233647, -0.68759395, -0.27585214, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179],\n",
       "       [-0.90810705, -0.68759395,  1.31254274, ..., -0.02038173,\n",
       "        -0.03918619, -0.00565179]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Scaler_pipeline__LIMIT_BAL', 'Scaler_pipeline__SEX',\n",
       "       'Scaler_pipeline__AGE', 'Scaler_pipeline__BILL_AMT_SEPT',\n",
       "       'Scaler_pipeline__BILL_AMT_AUG', 'Scaler_pipeline__BILL_AMT_JUL',\n",
       "       'Scaler_pipeline__BILL_AMT_JUN', 'Scaler_pipeline__BILL_AMT_MAY',\n",
       "       'Scaler_pipeline__BILL_AMT_APR', 'Scaler_pipeline__PAY_AMT_SEPT',\n",
       "       'Scaler_pipeline__PAY_AMT_AUG', 'Scaler_pipeline__PAY_AMT_JUL',\n",
       "       'Scaler_pipeline__PAY_AMT_JUN', 'Scaler_pipeline__PAY_AMT_MAY',\n",
       "       'Scaler_pipeline__PAY_AMT_APR',\n",
       "       'Scaler_pipeline__EDUCATION_Graduate School',\n",
       "       'Scaler_pipeline__EDUCATION_High School',\n",
       "       'Scaler_pipeline__EDUCATION_University',\n",
       "       'Scaler_pipeline__MARRIAGE_Married',\n",
       "       'Scaler_pipeline__MARRIAGE_Single', 'Scaler_pipeline__PAY_SEPT_-1',\n",
       "       'Scaler_pipeline__PAY_SEPT_0', 'Scaler_pipeline__PAY_SEPT_1',\n",
       "       'Scaler_pipeline__PAY_SEPT_2', 'Scaler_pipeline__PAY_SEPT_3',\n",
       "       'Scaler_pipeline__PAY_SEPT_4', 'Scaler_pipeline__PAY_SEPT_5',\n",
       "       'Scaler_pipeline__PAY_SEPT_6', 'Scaler_pipeline__PAY_SEPT_7',\n",
       "       'Scaler_pipeline__PAY_SEPT_8', 'Scaler_pipeline__PAY_AUG_-1',\n",
       "       'Scaler_pipeline__PAY_AUG_0', 'Scaler_pipeline__PAY_AUG_1',\n",
       "       'Scaler_pipeline__PAY_AUG_2', 'Scaler_pipeline__PAY_AUG_3',\n",
       "       'Scaler_pipeline__PAY_AUG_4', 'Scaler_pipeline__PAY_AUG_5',\n",
       "       'Scaler_pipeline__PAY_AUG_6', 'Scaler_pipeline__PAY_AUG_7',\n",
       "       'Scaler_pipeline__PAY_AUG_8', 'Scaler_pipeline__PAY_JUL_-1',\n",
       "       'Scaler_pipeline__PAY_JUL_0', 'Scaler_pipeline__PAY_JUL_1',\n",
       "       'Scaler_pipeline__PAY_JUL_2', 'Scaler_pipeline__PAY_JUL_3',\n",
       "       'Scaler_pipeline__PAY_JUL_4', 'Scaler_pipeline__PAY_JUL_5',\n",
       "       'Scaler_pipeline__PAY_JUL_6', 'Scaler_pipeline__PAY_JUL_7',\n",
       "       'Scaler_pipeline__PAY_JUL_8', 'Scaler_pipeline__PAY_JUN_-1',\n",
       "       'Scaler_pipeline__PAY_JUN_0', 'Scaler_pipeline__PAY_JUN_1',\n",
       "       'Scaler_pipeline__PAY_JUN_2', 'Scaler_pipeline__PAY_JUN_3',\n",
       "       'Scaler_pipeline__PAY_JUN_4', 'Scaler_pipeline__PAY_JUN_5',\n",
       "       'Scaler_pipeline__PAY_JUN_6', 'Scaler_pipeline__PAY_JUN_7',\n",
       "       'Scaler_pipeline__PAY_JUN_8', 'Scaler_pipeline__PAY_MAY_-1',\n",
       "       'Scaler_pipeline__PAY_MAY_0', 'Scaler_pipeline__PAY_MAY_2',\n",
       "       'Scaler_pipeline__PAY_MAY_3', 'Scaler_pipeline__PAY_MAY_4',\n",
       "       'Scaler_pipeline__PAY_MAY_5', 'Scaler_pipeline__PAY_MAY_6',\n",
       "       'Scaler_pipeline__PAY_MAY_7', 'Scaler_pipeline__PAY_MAY_8',\n",
       "       'Scaler_pipeline__PAY_APR_-1', 'Scaler_pipeline__PAY_APR_0',\n",
       "       'Scaler_pipeline__PAY_APR_2', 'Scaler_pipeline__PAY_APR_3',\n",
       "       'Scaler_pipeline__PAY_APR_4', 'Scaler_pipeline__PAY_APR_5',\n",
       "       'Scaler_pipeline__PAY_APR_6', 'Scaler_pipeline__PAY_APR_7',\n",
       "       'Scaler_pipeline__PAY_APR_8'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler_pipeline__LIMIT_BAL</th>\n",
       "      <th>Scaler_pipeline__SEX</th>\n",
       "      <th>Scaler_pipeline__AGE</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_SEPT</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_AUG</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_JUL</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_JUN</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_MAY</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_APR</th>\n",
       "      <th>Scaler_pipeline__PAY_AMT_SEPT</th>\n",
       "      <th>...</th>\n",
       "      <th>Scaler_pipeline__PAY_MAY_8</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_-1</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_0</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_2</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_3</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_4</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_5</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_6</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_7</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.636603</td>\n",
       "      <td>1.454347</td>\n",
       "      <td>-0.275852</td>\n",
       "      <td>2.120286</td>\n",
       "      <td>2.276774</td>\n",
       "      <td>2.202136</td>\n",
       "      <td>2.701267</td>\n",
       "      <td>-0.615909</td>\n",
       "      <td>-0.650032</td>\n",
       "      <td>0.374686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.416005</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.987629</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>0.291432</td>\n",
       "      <td>-0.302971</td>\n",
       "      <td>-0.299180</td>\n",
       "      <td>-0.262703</td>\n",
       "      <td>-0.279994</td>\n",
       "      <td>-0.255874</td>\n",
       "      <td>-0.232020</td>\n",
       "      <td>-0.337365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.828585</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>0.064518</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>-0.012692</td>\n",
       "      <td>-0.190511</td>\n",
       "      <td>-0.225896</td>\n",
       "      <td>-0.188472</td>\n",
       "      <td>-0.154340</td>\n",
       "      <td>-0.202012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.682336</td>\n",
       "      <td>1.454347</td>\n",
       "      <td>-0.389309</td>\n",
       "      <td>-0.681787</td>\n",
       "      <td>-0.679479</td>\n",
       "      <td>-0.674533</td>\n",
       "      <td>-0.665678</td>\n",
       "      <td>-0.656790</td>\n",
       "      <td>-0.650032</td>\n",
       "      <td>-0.339163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.293989</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>0.858716</td>\n",
       "      <td>-0.655572</td>\n",
       "      <td>-0.651252</td>\n",
       "      <td>-0.532371</td>\n",
       "      <td>-0.586336</td>\n",
       "      <td>-0.537510</td>\n",
       "      <td>1.114532</td>\n",
       "      <td>-0.195194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.416005</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31302</th>\n",
       "      <td>0.682336</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.389309</td>\n",
       "      <td>-0.677112</td>\n",
       "      <td>-0.679479</td>\n",
       "      <td>-0.674533</td>\n",
       "      <td>-0.665678</td>\n",
       "      <td>-0.656790</td>\n",
       "      <td>-0.650032</td>\n",
       "      <td>-0.339163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31303</th>\n",
       "      <td>-0.192407</td>\n",
       "      <td>1.454347</td>\n",
       "      <td>-0.956593</td>\n",
       "      <td>-0.598564</td>\n",
       "      <td>-0.550189</td>\n",
       "      <td>-0.625240</td>\n",
       "      <td>-0.627953</td>\n",
       "      <td>-0.631117</td>\n",
       "      <td>-0.625486</td>\n",
       "      <td>0.321265</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.416005</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31304</th>\n",
       "      <td>0.841381</td>\n",
       "      <td>1.454347</td>\n",
       "      <td>0.177975</td>\n",
       "      <td>-0.184513</td>\n",
       "      <td>-0.369060</td>\n",
       "      <td>-0.103828</td>\n",
       "      <td>-0.047816</td>\n",
       "      <td>0.631582</td>\n",
       "      <td>0.233276</td>\n",
       "      <td>-0.218787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31305</th>\n",
       "      <td>-0.828585</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-1.523877</td>\n",
       "      <td>-0.043431</td>\n",
       "      <td>-0.049201</td>\n",
       "      <td>0.018439</td>\n",
       "      <td>-0.227613</td>\n",
       "      <td>-0.197577</td>\n",
       "      <td>-0.167367</td>\n",
       "      <td>-0.175338</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31306</th>\n",
       "      <td>-0.590018</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.389309</td>\n",
       "      <td>-0.367233</td>\n",
       "      <td>-0.347346</td>\n",
       "      <td>-0.323406</td>\n",
       "      <td>-0.267558</td>\n",
       "      <td>-0.223443</td>\n",
       "      <td>-0.195823</td>\n",
       "      <td>-0.248963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31307 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Scaler_pipeline__LIMIT_BAL  Scaler_pipeline__SEX  Scaler_pipeline__AGE  \\\n",
       "0                        1.636603              1.454347             -0.275852   \n",
       "1                       -0.987629             -0.687594              0.291432   \n",
       "2                       -0.828585             -0.687594              0.064518   \n",
       "3                        0.682336              1.454347             -0.389309   \n",
       "4                       -0.293989             -0.687594              0.858716   \n",
       "...                           ...                   ...                   ...   \n",
       "31302                    0.682336             -0.687594             -0.389309   \n",
       "31303                   -0.192407              1.454347             -0.956593   \n",
       "31304                    0.841381              1.454347              0.177975   \n",
       "31305                   -0.828585             -0.687594             -1.523877   \n",
       "31306                   -0.590018             -0.687594             -0.389309   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_SEPT  Scaler_pipeline__BILL_AMT_AUG  \\\n",
       "0                            2.120286                       2.276774   \n",
       "1                           -0.302971                      -0.299180   \n",
       "2                            0.002873                      -0.012692   \n",
       "3                           -0.681787                      -0.679479   \n",
       "4                           -0.655572                      -0.651252   \n",
       "...                               ...                            ...   \n",
       "31302                       -0.677112                      -0.679479   \n",
       "31303                       -0.598564                      -0.550189   \n",
       "31304                       -0.184513                      -0.369060   \n",
       "31305                       -0.043431                      -0.049201   \n",
       "31306                       -0.367233                      -0.347346   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_JUL  Scaler_pipeline__BILL_AMT_JUN  \\\n",
       "0                           2.202136                       2.701267   \n",
       "1                          -0.262703                      -0.279994   \n",
       "2                          -0.190511                      -0.225896   \n",
       "3                          -0.674533                      -0.665678   \n",
       "4                          -0.532371                      -0.586336   \n",
       "...                              ...                            ...   \n",
       "31302                      -0.674533                      -0.665678   \n",
       "31303                      -0.625240                      -0.627953   \n",
       "31304                      -0.103828                      -0.047816   \n",
       "31305                       0.018439                      -0.227613   \n",
       "31306                      -0.323406                      -0.267558   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_MAY  Scaler_pipeline__BILL_AMT_APR  \\\n",
       "0                          -0.615909                      -0.650032   \n",
       "1                          -0.255874                      -0.232020   \n",
       "2                          -0.188472                      -0.154340   \n",
       "3                          -0.656790                      -0.650032   \n",
       "4                          -0.537510                       1.114532   \n",
       "...                              ...                            ...   \n",
       "31302                      -0.656790                      -0.650032   \n",
       "31303                      -0.631117                      -0.625486   \n",
       "31304                       0.631582                       0.233276   \n",
       "31305                      -0.197577                      -0.167367   \n",
       "31306                      -0.223443                      -0.195823   \n",
       "\n",
       "       Scaler_pipeline__PAY_AMT_SEPT  ...  Scaler_pipeline__PAY_MAY_8  \\\n",
       "0                           0.374686  ...                         0.0   \n",
       "1                          -0.337365  ...                         0.0   \n",
       "2                          -0.202012  ...                         0.0   \n",
       "3                          -0.339163  ...                         0.0   \n",
       "4                          -0.195194  ...                         0.0   \n",
       "...                              ...  ...                         ...   \n",
       "31302                      -0.339163  ...                         0.0   \n",
       "31303                       0.321265  ...                         0.0   \n",
       "31304                      -0.218787  ...                         0.0   \n",
       "31305                      -0.175338  ...                         0.0   \n",
       "31306                      -0.248963  ...                         0.0   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_-1  Scaler_pipeline__PAY_APR_0  \\\n",
       "0                         2.416005                   -0.923954   \n",
       "1                        -0.413906                    1.082304   \n",
       "2                        -0.413906                    1.082304   \n",
       "3                        -0.413906                   -0.923954   \n",
       "4                         2.416005                   -0.923954   \n",
       "...                            ...                         ...   \n",
       "31302                    -0.413906                   -0.923954   \n",
       "31303                     2.416005                   -0.923954   \n",
       "31304                    -0.413906                    1.082304   \n",
       "31305                    -0.413906                    1.082304   \n",
       "31306                    -0.413906                   -0.923954   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_2  Scaler_pipeline__PAY_APR_3  \\\n",
       "0                       -0.318235                   -0.067501   \n",
       "1                       -0.318235                   -0.067501   \n",
       "2                       -0.318235                   -0.067501   \n",
       "3                       -0.318235                   -0.067501   \n",
       "4                       -0.318235                   -0.067501   \n",
       "...                           ...                         ...   \n",
       "31302                   -0.318235                   -0.067501   \n",
       "31303                   -0.318235                   -0.067501   \n",
       "31304                   -0.318235                   -0.067501   \n",
       "31305                   -0.318235                   -0.067501   \n",
       "31306                   -0.318235                   -0.067501   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_4  Scaler_pipeline__PAY_APR_5  \\\n",
       "0                       -0.033455                   -0.015987   \n",
       "1                       -0.033455                   -0.015987   \n",
       "2                       -0.033455                   -0.015987   \n",
       "3                       -0.033455                   -0.015987   \n",
       "4                       -0.033455                   -0.015987   \n",
       "...                           ...                         ...   \n",
       "31302                   -0.033455                   -0.015987   \n",
       "31303                   -0.033455                   -0.015987   \n",
       "31304                   -0.033455                   -0.015987   \n",
       "31305                   -0.033455                   -0.015987   \n",
       "31306                   -0.033455                   -0.015987   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_6  Scaler_pipeline__PAY_APR_7  \\\n",
       "0                       -0.020382                   -0.039186   \n",
       "1                       -0.020382                   -0.039186   \n",
       "2                       -0.020382                   -0.039186   \n",
       "3                       -0.020382                   -0.039186   \n",
       "4                       -0.020382                   -0.039186   \n",
       "...                           ...                         ...   \n",
       "31302                   -0.020382                   -0.039186   \n",
       "31303                   -0.020382                   -0.039186   \n",
       "31304                   -0.020382                   -0.039186   \n",
       "31305                   -0.020382                   -0.039186   \n",
       "31306                   -0.020382                   -0.039186   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_8  \n",
       "0                       -0.005652  \n",
       "1                       -0.005652  \n",
       "2                       -0.005652  \n",
       "3                       -0.005652  \n",
       "4                       -0.005652  \n",
       "...                           ...  \n",
       "31302                   -0.005652  \n",
       "31303                   -0.005652  \n",
       "31304                   -0.005652  \n",
       "31305                   -0.005652  \n",
       "31306                   -0.005652  \n",
       "\n",
       "[31307 rows x 78 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scaler_pipeline__LIMIT_BAL</th>\n",
       "      <th>Scaler_pipeline__SEX</th>\n",
       "      <th>Scaler_pipeline__AGE</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_SEPT</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_AUG</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_JUL</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_JUN</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_MAY</th>\n",
       "      <th>Scaler_pipeline__BILL_AMT_APR</th>\n",
       "      <th>Scaler_pipeline__PAY_AMT_SEPT</th>\n",
       "      <th>...</th>\n",
       "      <th>Scaler_pipeline__PAY_MAY_8</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_-1</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_0</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_2</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_3</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_4</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_5</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_6</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_7</th>\n",
       "      <th>Scaler_pipeline__PAY_APR_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.205203</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.275852</td>\n",
       "      <td>-0.264304</td>\n",
       "      <td>-0.243736</td>\n",
       "      <td>-0.221974</td>\n",
       "      <td>-0.154733</td>\n",
       "      <td>-0.288432</td>\n",
       "      <td>-0.426854</td>\n",
       "      <td>-0.196707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.416005</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.284726</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>1.426000</td>\n",
       "      <td>1.298871</td>\n",
       "      <td>1.303623</td>\n",
       "      <td>1.297250</td>\n",
       "      <td>0.925735</td>\n",
       "      <td>0.465063</td>\n",
       "      <td>0.119261</td>\n",
       "      <td>0.067123</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112885</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>0.404889</td>\n",
       "      <td>-0.681787</td>\n",
       "      <td>-0.668348</td>\n",
       "      <td>-0.671776</td>\n",
       "      <td>-0.615171</td>\n",
       "      <td>-0.123418</td>\n",
       "      <td>-0.306916</td>\n",
       "      <td>-0.282394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.795647</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>0.972172</td>\n",
       "      <td>-0.583672</td>\n",
       "      <td>-0.612837</td>\n",
       "      <td>-0.608959</td>\n",
       "      <td>-0.606526</td>\n",
       "      <td>-0.589810</td>\n",
       "      <td>-0.582132</td>\n",
       "      <td>-0.232321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.416005</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000425</td>\n",
       "      <td>1.454347</td>\n",
       "      <td>-0.502766</td>\n",
       "      <td>1.328059</td>\n",
       "      <td>1.425413</td>\n",
       "      <td>1.556657</td>\n",
       "      <td>1.739491</td>\n",
       "      <td>1.692735</td>\n",
       "      <td>1.786470</td>\n",
       "      <td>0.016978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15416</th>\n",
       "      <td>-0.669541</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.275852</td>\n",
       "      <td>0.035709</td>\n",
       "      <td>-0.065275</td>\n",
       "      <td>-0.189310</td>\n",
       "      <td>-0.279499</td>\n",
       "      <td>-0.482128</td>\n",
       "      <td>-0.525693</td>\n",
       "      <td>-0.195923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15417</th>\n",
       "      <td>0.221314</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.616222</td>\n",
       "      <td>0.833578</td>\n",
       "      <td>0.888419</td>\n",
       "      <td>0.914203</td>\n",
       "      <td>1.055028</td>\n",
       "      <td>1.128321</td>\n",
       "      <td>1.133541</td>\n",
       "      <td>0.052592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>3.142334</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15418</th>\n",
       "      <td>-0.590018</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-1.523877</td>\n",
       "      <td>0.354494</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.479414</td>\n",
       "      <td>0.508275</td>\n",
       "      <td>-0.180505</td>\n",
       "      <td>-0.504945</td>\n",
       "      <td>-0.141149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15419</th>\n",
       "      <td>0.682336</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>-0.275852</td>\n",
       "      <td>2.563539</td>\n",
       "      <td>2.630527</td>\n",
       "      <td>2.788309</td>\n",
       "      <td>2.909462</td>\n",
       "      <td>2.561892</td>\n",
       "      <td>2.715074</td>\n",
       "      <td>0.343346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>1.082304</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15420</th>\n",
       "      <td>-0.908107</td>\n",
       "      <td>-0.687594</td>\n",
       "      <td>1.312543</td>\n",
       "      <td>-0.676023</td>\n",
       "      <td>-0.673543</td>\n",
       "      <td>-0.668366</td>\n",
       "      <td>-0.659094</td>\n",
       "      <td>-0.642891</td>\n",
       "      <td>-0.642921</td>\n",
       "      <td>-0.308892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.413906</td>\n",
       "      <td>-0.923954</td>\n",
       "      <td>-0.318235</td>\n",
       "      <td>-0.067501</td>\n",
       "      <td>-0.033455</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>-0.020382</td>\n",
       "      <td>-0.039186</td>\n",
       "      <td>-0.005652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15421 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Scaler_pipeline__LIMIT_BAL  Scaler_pipeline__SEX  Scaler_pipeline__AGE  \\\n",
       "0                        0.205203             -0.687594             -0.275852   \n",
       "1                        0.284726             -0.687594              1.426000   \n",
       "2                       -0.112885             -0.687594              0.404889   \n",
       "3                        1.795647             -0.687594              0.972172   \n",
       "4                        1.000425              1.454347             -0.502766   \n",
       "...                           ...                   ...                   ...   \n",
       "15416                   -0.669541             -0.687594             -0.275852   \n",
       "15417                    0.221314             -0.687594             -0.616222   \n",
       "15418                   -0.590018             -0.687594             -1.523877   \n",
       "15419                    0.682336             -0.687594             -0.275852   \n",
       "15420                   -0.908107             -0.687594              1.312543   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_SEPT  Scaler_pipeline__BILL_AMT_AUG  \\\n",
       "0                           -0.264304                      -0.243736   \n",
       "1                            1.298871                       1.303623   \n",
       "2                           -0.681787                      -0.668348   \n",
       "3                           -0.583672                      -0.612837   \n",
       "4                            1.328059                       1.425413   \n",
       "...                               ...                            ...   \n",
       "15416                        0.035709                      -0.065275   \n",
       "15417                        0.833578                       0.888419   \n",
       "15418                        0.354494                       0.396443   \n",
       "15419                        2.563539                       2.630527   \n",
       "15420                       -0.676023                      -0.673543   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_JUL  Scaler_pipeline__BILL_AMT_JUN  \\\n",
       "0                          -0.221974                      -0.154733   \n",
       "1                           1.297250                       0.925735   \n",
       "2                          -0.671776                      -0.615171   \n",
       "3                          -0.608959                      -0.606526   \n",
       "4                           1.556657                       1.739491   \n",
       "...                              ...                            ...   \n",
       "15416                      -0.189310                      -0.279499   \n",
       "15417                       0.914203                       1.055028   \n",
       "15418                       0.479414                       0.508275   \n",
       "15419                       2.788309                       2.909462   \n",
       "15420                      -0.668366                      -0.659094   \n",
       "\n",
       "       Scaler_pipeline__BILL_AMT_MAY  Scaler_pipeline__BILL_AMT_APR  \\\n",
       "0                          -0.288432                      -0.426854   \n",
       "1                           0.465063                       0.119261   \n",
       "2                          -0.123418                      -0.306916   \n",
       "3                          -0.589810                      -0.582132   \n",
       "4                           1.692735                       1.786470   \n",
       "...                              ...                            ...   \n",
       "15416                      -0.482128                      -0.525693   \n",
       "15417                       1.128321                       1.133541   \n",
       "15418                      -0.180505                      -0.504945   \n",
       "15419                       2.561892                       2.715074   \n",
       "15420                      -0.642891                      -0.642921   \n",
       "\n",
       "       Scaler_pipeline__PAY_AMT_SEPT  ...  Scaler_pipeline__PAY_MAY_8  \\\n",
       "0                          -0.196707  ...                         0.0   \n",
       "1                           0.067123  ...                         0.0   \n",
       "2                          -0.282394  ...                         0.0   \n",
       "3                          -0.232321  ...                         0.0   \n",
       "4                           0.016978  ...                         0.0   \n",
       "...                              ...  ...                         ...   \n",
       "15416                      -0.195923  ...                         0.0   \n",
       "15417                       0.052592  ...                         0.0   \n",
       "15418                      -0.141149  ...                         0.0   \n",
       "15419                       0.343346  ...                         0.0   \n",
       "15420                      -0.308892  ...                         0.0   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_-1  Scaler_pipeline__PAY_APR_0  \\\n",
       "0                         2.416005                   -0.923954   \n",
       "1                        -0.413906                    1.082304   \n",
       "2                        -0.413906                    1.082304   \n",
       "3                         2.416005                   -0.923954   \n",
       "4                        -0.413906                    1.082304   \n",
       "...                            ...                         ...   \n",
       "15416                    -0.413906                    1.082304   \n",
       "15417                    -0.413906                   -0.923954   \n",
       "15418                    -0.413906                    1.082304   \n",
       "15419                    -0.413906                    1.082304   \n",
       "15420                    -0.413906                   -0.923954   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_2  Scaler_pipeline__PAY_APR_3  \\\n",
       "0                       -0.318235                   -0.067501   \n",
       "1                       -0.318235                   -0.067501   \n",
       "2                       -0.318235                   -0.067501   \n",
       "3                       -0.318235                   -0.067501   \n",
       "4                       -0.318235                   -0.067501   \n",
       "...                           ...                         ...   \n",
       "15416                   -0.318235                   -0.067501   \n",
       "15417                    3.142334                   -0.067501   \n",
       "15418                   -0.318235                   -0.067501   \n",
       "15419                   -0.318235                   -0.067501   \n",
       "15420                   -0.318235                   -0.067501   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_4  Scaler_pipeline__PAY_APR_5  \\\n",
       "0                       -0.033455                   -0.015987   \n",
       "1                       -0.033455                   -0.015987   \n",
       "2                       -0.033455                   -0.015987   \n",
       "3                       -0.033455                   -0.015987   \n",
       "4                       -0.033455                   -0.015987   \n",
       "...                           ...                         ...   \n",
       "15416                   -0.033455                   -0.015987   \n",
       "15417                   -0.033455                   -0.015987   \n",
       "15418                   -0.033455                   -0.015987   \n",
       "15419                   -0.033455                   -0.015987   \n",
       "15420                   -0.033455                   -0.015987   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_6  Scaler_pipeline__PAY_APR_7  \\\n",
       "0                       -0.020382                   -0.039186   \n",
       "1                       -0.020382                   -0.039186   \n",
       "2                       -0.020382                   -0.039186   \n",
       "3                       -0.020382                   -0.039186   \n",
       "4                       -0.020382                   -0.039186   \n",
       "...                           ...                         ...   \n",
       "15416                   -0.020382                   -0.039186   \n",
       "15417                   -0.020382                   -0.039186   \n",
       "15418                   -0.020382                   -0.039186   \n",
       "15419                   -0.020382                   -0.039186   \n",
       "15420                   -0.020382                   -0.039186   \n",
       "\n",
       "       Scaler_pipeline__PAY_APR_8  \n",
       "0                       -0.005652  \n",
       "1                       -0.005652  \n",
       "2                       -0.005652  \n",
       "3                       -0.005652  \n",
       "4                       -0.005652  \n",
       "...                           ...  \n",
       "15416                   -0.005652  \n",
       "15417                   -0.005652  \n",
       "15418                   -0.005652  \n",
       "15419                   -0.005652  \n",
       "15420                   -0.005652  \n",
       "\n",
       "[15421 rows x 78 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(model,X_test, X_train, y_test, y_train):\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    accuracy_train = accuracy_score(y_train, y_train_pred)\n",
    "    accuracy_test = accuracy_score(y_test, y_test_pred)\n",
    "    precision = precision_score(y_test, y_test_pred)\n",
    "    recall = recall_score(y_test, y_test_pred)\n",
    "    f1 = f1_score(y_test, y_test_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_test_pred)\n",
    "    return accuracy_train,accuracy_test, precision, recall, f1, roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train multiple models\n",
    "models = {\n",
    "            'LogisticRegression': LogisticRegression(fit_intercept=True, max_iter=10000),\n",
    "            'DecisionTree': DecisionTreeClassifier(),\n",
    "            'Random Forest': RandomForestClassifier(),\n",
    "            'SVM': SVC(probability=True),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(),\n",
    "            'XG Boosting' : XGBClassifier()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = []\n",
    "accuracy_train_list = []\n",
    "accuracy_test_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "confusion_list=[]\n",
    "roc_auc_list=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogisticRegression',\n",
       " 'DecisionTree',\n",
       " 'Random Forest',\n",
       " 'SVM',\n",
       " 'Gradient Boosting',\n",
       " 'XG Boosting']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n",
      "DecisionTreeClassifier()\n",
      "RandomForestClassifier()\n",
      "SVC(probability=True)\n",
      "GradientBoostingClassifier()\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, gamma=None, gpu_id=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
      "              tree_method=None, validate_parameters=None, verbosity=None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['LogisticRegression', 'DecisionTree', 'Random Forest', 'SVM', 'Gradient Boosting', 'XG Boosting'])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([LogisticRegression(max_iter=10000), DecisionTreeClassifier(), RandomForestClassifier(), SVC(probability=True), GradientBoostingClassifier(), XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=None,\n",
       "              enable_categorical=False, gamma=None, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, reg_alpha=None,\n",
       "              reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "              tree_method=None, validate_parameters=None, verbosity=None)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: LogisticRegression\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.826524419458907\n",
      "The accuracy on test data is: 0.8296478827572791\n",
      "The Precision on test data is : 0.8584120716401071\n",
      "The Recall on test data is : 0.7894941634241245\n",
      "The F1 Score on test data is : 0.8225119924329437\n",
      "The roc_score on test data is : 0.829645279092428\n",
      "===================================\n",
      "\n",
      "\n",
      "1: DecisionTree\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.9995528156642285\n",
      "The accuracy on test data is: 0.7869787951494716\n",
      "The Precision on test data is : 0.7768047041161016\n",
      "The Recall on test data is : 0.8053177691309987\n",
      "The F1 Score on test data is : 0.79080430490989\n",
      "The roc_score on test data is : 0.7869799842931611\n",
      "===================================\n",
      "\n",
      "\n",
      "2: Random Forest\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.9995528156642285\n",
      "The accuracy on test data is: 0.8679073990013618\n",
      "The Precision on test data is : 0.8993383077572856\n",
      "The Recall on test data is : 0.8285343709468224\n",
      "The F1 Score on test data is : 0.8624856544926753\n",
      "The roc_score on test data is : 0.8679048459584326\n",
      "===================================\n",
      "\n",
      "\n",
      "3: SVM\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8465518893538186\n",
      "The accuracy on test data is: 0.8380779456585176\n",
      "The Precision on test data is : 0.900938317181972\n",
      "The Recall on test data is : 0.759662775616083\n",
      "The F1 Score on test data is : 0.8242910421504469\n",
      "The roc_score on test data is : 0.8380728610281167\n",
      "===================================\n",
      "\n",
      "\n",
      "4: Gradient Boosting\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8466796563068962\n",
      "The accuracy on test data is: 0.8459243888204396\n",
      "The Precision on test data is : 0.8820916905444126\n",
      "The Recall on test data is : 0.7985732814526589\n",
      "The F1 Score on test data is : 0.8382573179033357\n",
      "The roc_score on test data is : 0.8459213184594381\n",
      "===================================\n",
      "\n",
      "\n",
      "[17:13:14] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "5: XG Boosting\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.9159932283514869\n",
      "The accuracy on test data is: 0.8574022436936645\n",
      "The Precision on test data is : 0.8947142243231628\n",
      "The Recall on test data is : 0.8101167315175097\n",
      "The F1 Score on test data is : 0.8503165203185623\n",
      "The roc_score on test data is : 0.8573991775860146\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models))):\n",
    "    model = list(models.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # This is a validation (test) score\n",
    "    accuracy_train,accuracy_test, precision, recall, f1, roc_auc = evaluate_classification_model(model,X_test, X_train, y_test, y_train)\n",
    "\n",
    "    print(f'{i}: {list(models.keys())[i]}')\n",
    "    model_list.append(list(models.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"The accuracy on train data is:\", accuracy_train)\n",
    "    print(\"The accuracy on test data is:\", accuracy_test)\n",
    "    print(\"The Precision on test data is :\", precision)\n",
    "    print(\"The Recall on test data is :\", recall)\n",
    "    print(\"The F1 Score on test data is :\", f1)\n",
    "    print(\"The roc_score on test data is :\", roc_auc)\n",
    "\n",
    "    accuracy_train_list.append(accuracy_train)\n",
    "    accuracy_test_list.append(accuracy_test)\n",
    "    precision_list.append(precision)\n",
    "    recall_list.append(recall)\n",
    "    f1_list.append(f1)\n",
    "    roc_auc_list.append(roc_auc)\n",
    "\n",
    "    print('='*65)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.DataFrame({'Classifier':model_list, \n",
    "                           'Train Accuracy': accuracy_train_list, \n",
    "                           'Test Accuracy': accuracy_test_list, \n",
    "                           'Precision': precision_list, \n",
    "                           'Recall': recall_list, \n",
    "                           'F1 Score': f1_list , \n",
    "                           'AUC': roc_auc_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.867907</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.828534</td>\n",
       "      <td>0.862486</td>\n",
       "      <td>0.867905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG Boosting</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.857402</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.810117</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.857399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.846680</td>\n",
       "      <td>0.845924</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.845921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.759663</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>0.838073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.826524</td>\n",
       "      <td>0.829648</td>\n",
       "      <td>0.858412</td>\n",
       "      <td>0.789494</td>\n",
       "      <td>0.822512</td>\n",
       "      <td>0.829645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.786979</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.786980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
       "2       Random Forest        0.999553       0.867907   0.899338  0.828534   \n",
       "5         XG Boosting        0.915993       0.857402   0.894714  0.810117   \n",
       "4   Gradient Boosting        0.846680       0.845924   0.882092  0.798573   \n",
       "3                 SVM        0.846552       0.838078   0.900938  0.759663   \n",
       "0  LogisticRegression        0.826524       0.829648   0.858412  0.789494   \n",
       "1        DecisionTree        0.999553       0.786979   0.776805  0.805318   \n",
       "\n",
       "   F1 Score       AUC  \n",
       "2  0.862486  0.867905  \n",
       "5  0.850317  0.857399  \n",
       "4  0.838257  0.845921  \n",
       "3  0.824291  0.838073  \n",
       "0  0.822512  0.829645  \n",
       "1  0.790804  0.786980  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.sort_values(by=['Test Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Random Forest shows highest test accuracy and F1 score.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Cross Validation & Hyperparameter Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# penalty in Logistic Regression Classifier\n",
    "penalties = ['l1','l2', 'elasticnet', 'none']\n",
    "\n",
    "# hyperparameter C\n",
    "C= [0.0001, 0.001, 0.1, 0.5, 0.75, 1, 1.25, 1.5, 5, 10]\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_dict = {'penalty':penalties,\n",
    "              'max_iter' : [100, 1000,2500, 5000],\n",
    "              'C' : C }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': [0.0001, 0.001, 0.1, 0.5, 0.75, 1, 1.25, 1.5, 5,\n",
       "                               10],\n",
       "                         'max_iter': [100, 1000, 2500, 5000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the Logistic Regression\n",
    "logi = LogisticRegression()\n",
    "\n",
    "# Grid search\n",
    "logi_grid = GridSearchCV(estimator=logi,\n",
    "                       param_grid = param_dict,\n",
    "                       cv = 5, verbose=3, n_jobs = -1, scoring='roc_auc')\n",
    "# fitting model\n",
    "logi_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1, 'max_iter': 100, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logi_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Decision Tree Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum depth of the tree\n",
    "depth_of_tree = [20,25,30,35]\n",
    "\n",
    "# The minimum number of samples required to split an internal node\n",
    "min_samples_split = [0.001,0.01,0.05]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [40,50,60]\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_dict = {'max_depth': depth_of_tree,\n",
    "              'min_samples_split':min_samples_split,\n",
    "              'min_samples_leaf': min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [20, 25, 30, 35],\n",
       "                         'min_samples_leaf': [40, 50, 60],\n",
       "                         'min_samples_split': [0.001, 0.01, 0.05]},\n",
       "             scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the decision tree\n",
    "dtc = DecisionTreeClassifier()\n",
    "\n",
    "# Grid search\n",
    "dtc_grid = GridSearchCV(estimator=dtc,\n",
    "                       param_grid = param_dict,\n",
    "                       cv = 5, verbose=3, n_jobs = -1, scoring='roc_auc')\n",
    "# fitting model\n",
    "dtc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 35, 'min_samples_leaf': 50, 'min_samples_split': 0.01}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "param_dict = {'C':[1, 10] ,\n",
    "              'kernel': ['rbf']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=SVC(probability=True), n_jobs=-1,\n",
       "                   param_distributions={'C': [1, 10], 'kernel': ['rbf']},\n",
       "                   scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the support vector classifier\n",
    "svm=SVC(probability=True)\n",
    "\n",
    "# Grid search\n",
    "svm_grid = RandomizedSearchCV(estimator = svm, param_distributions = param_dict,\n",
    "                       cv = 2, verbose=2, n_jobs = -1, scoring= 'roc_auc')\n",
    "# fitting model\n",
    "svm_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kernel': 'rbf', 'C': 1}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Random Forest Classifer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees\n",
    "n_estimators = [100,150,200]\n",
    "\n",
    "# Maximum depth of trees\n",
    "max_depth = [10,20,30]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [50,100,150]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [40,50]\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_dict = {'n_estimators' : n_estimators,\n",
    "              'max_depth' : max_depth,\n",
    "              'min_samples_split' : min_samples_split,\n",
    "              'min_samples_leaf' : min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   5.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   8.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   7.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   6.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   5.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   6.1s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   6.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   6.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   7.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   3.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   4.9s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.3s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.6s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.5s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=10, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   7.2s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   7.5s\n",
      "[CV] END max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   6.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   3.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   6.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   4.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=   2.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=150; total time=   4.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   6.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=150; total time=   4.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.3s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=50, n_estimators=200; total time=   5.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.6s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.9s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.2s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.4s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=   2.5s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.8s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=150; total time=   3.7s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.0s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.1s\n",
      "[CV] END max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=200; total time=   5.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [10, 20, 30],\n",
       "                         'min_samples_leaf': [40, 50],\n",
       "                         'min_samples_split': [50, 100, 150],\n",
       "                         'n_estimators': [100, 150, 200]},\n",
       "             scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Grid search\n",
    "rfc_grid = GridSearchCV(estimator=rfc,\n",
    "                       param_grid = param_dict,\n",
    "                       cv = 5, verbose=2, scoring='roc_auc')\n",
    "# fitting model\n",
    "rfc_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_samples_leaf': 40,\n",
       " 'min_samples_split': 50,\n",
       " 'n_estimators': 200}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to shrinks the contribution of each tree by learning_rate\n",
    "learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\n",
    "\n",
    "# Number of trees\n",
    "n_estimators = [100,150,200]\n",
    "\n",
    "# Maximum depth of trees\n",
    "max_depth = [10,20,30]\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [50,100,150]\n",
    "\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [40,50]\n",
    "\n",
    "# Hyperparameter Grid\n",
    "param_dict = {'learning_rate': learning_rates,\n",
    "              'n_estimators' : n_estimators,\n",
    "              'max_depth' : max_depth,\n",
    "              'min_samples_split' : min_samples_split,\n",
    "              'min_samples_leaf' : min_samples_leaf}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n",
      "[CV] END learning_rate=1, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  30.3s\n",
      "[CV] END learning_rate=1, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  30.4s\n",
      "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time= 1.0min\n",
      "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=150, n_estimators=200; total time= 1.3min\n",
      "[CV] END learning_rate=0.1, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=  37.4s\n",
      "[CV] END learning_rate=0.1, max_depth=30, min_samples_leaf=40, min_samples_split=150, n_estimators=100; total time=  37.8s\n",
      "[CV] END learning_rate=0.01, max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=  37.5s\n",
      "[CV] END learning_rate=0.01, max_depth=10, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time=  40.7s\n",
      "[CV] END learning_rate=1, max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=  42.3s\n",
      "[CV] END learning_rate=1, max_depth=10, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time=  41.1s\n",
      "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time= 1.2min\n",
      "[CV] END learning_rate=0.25, max_depth=20, min_samples_leaf=40, min_samples_split=50, n_estimators=200; total time= 1.2min\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=40, min_samples_split=100, n_estimators=200; total time= 1.1min\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  25.0s\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  25.0s\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time= 1.0min\n",
      "[CV] END learning_rate=0.05, max_depth=20, min_samples_leaf=50, min_samples_split=100, n_estimators=200; total time= 1.0min\n",
      "[CV] END learning_rate=1, max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  41.7s\n",
      "[CV] END learning_rate=1, max_depth=30, min_samples_leaf=50, min_samples_split=150, n_estimators=100; total time=  42.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=2, estimator=GradientBoostingClassifier(random_state=42),\n",
       "                   param_distributions={'learning_rate': [1, 0.5, 0.25, 0.1,\n",
       "                                                          0.05, 0.01],\n",
       "                                        'max_depth': [10, 20, 30],\n",
       "                                        'min_samples_leaf': [40, 50],\n",
       "                                        'min_samples_split': [50, 100, 150],\n",
       "                                        'n_estimators': [100, 150, 200]},\n",
       "                   scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier\n",
    "gbc = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Grid search\n",
    "gbc_grid = RandomizedSearchCV(estimator=gbc,\n",
    "                       param_distributions = param_dict,\n",
    "                       cv = 2, verbose=2, scoring='roc_auc')\n",
    "# fitting model\n",
    "gbc_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 200,\n",
       " 'min_samples_split': 100,\n",
       " 'min_samples_leaf': 40,\n",
       " 'max_depth': 20,\n",
       " 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(learning_rate=0.05, max_depth=20,\n",
       "                           min_samples_leaf=40, min_samples_split=100,\n",
       "                           n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbc_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. XG Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Grid\n",
    "param_dict = {'learning_rate': [0.15, 0.1, 0.05],\n",
    "              'n_estimators' : [200, 250],\n",
    "              'max_depth' : [15,20,25],\n",
    "              'min_child_weight' : [1,3],\n",
    "              'gamma': [0.3, 0.2, 0.1],\n",
    "              'min_samples_leaf' : [40, 50]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[17:02:04] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:02:04] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           enable_categorical=False, gamma=None,\n",
       "                                           gpu_id=None, importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=None,\n",
       "                                           min_child_weight=None, missing=nan,\n",
       "                                           monotone_constraints...\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None,\n",
       "                                           scale_pos_weight=None,\n",
       "                                           subsample=None, tree_method=None,\n",
       "                                           validate_parameters=None,\n",
       "                                           verbosity=None),\n",
       "                   n_iter=5, n_jobs=-1,\n",
       "                   param_distributions={'gamma': [0.3, 0.2, 0.1],\n",
       "                                        'learning_rate': [0.15, 0.1, 0.05],\n",
       "                                        'max_depth': [15, 20, 25],\n",
       "                                        'min_child_weight': [1, 3],\n",
       "                                        'min_samples_leaf': [40, 50],\n",
       "                                        'n_estimators': [200, 250]},\n",
       "                   scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an instance of the RandomForestClassifier\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "# Grid search\n",
    "xgb_grid = RandomizedSearchCV(estimator=xgb,\n",
    "                       param_distributions = param_dict,\n",
    "                       n_jobs=-1, n_iter=5, cv = 3,\n",
    "                       verbose=2, scoring='roc_auc')\n",
    "# fitting model\n",
    "xgb_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 250,\n",
       " 'min_samples_leaf': 40,\n",
       " 'min_child_weight': 1,\n",
       " 'max_depth': 15,\n",
       " 'learning_rate': 0.05,\n",
       " 'gamma': 0.1}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train multiple models\n",
    "models2 = {\n",
    "            'Optimal Logistic Regression': LogisticRegression(C= 0.1, max_iter= 100, penalty= 'l2'),\n",
    "            'Optimal Decision Tree': DecisionTreeClassifier(max_depth= 35, min_samples_leaf= 50, min_samples_split= 0.01),\n",
    "            'Optimal Random Forest':RandomForestClassifier(max_depth= 20, min_samples_leaf= 40, min_samples_split= 50, n_estimators = 200),\n",
    "            'Optimal SVM': SVC(kernel= 'rbf', C= 1),\n",
    "            'Optimal Gradient Boosting': GradientBoostingClassifier(learning_rate=0.05, max_depth=20,\n",
    "                           min_samples_leaf=40, min_samples_split=100,\n",
    "                           n_estimators=200, random_state=42),\n",
    "            'Optimal XG Boosting' : XGBClassifier(n_estimators= 250, min_samples_leaf=40, min_child_weight= 1, max_depth= 15, learning_rate = 0.05, gamma= 0.1)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list2 = []\n",
    "accuracy_train_list2 = []\n",
    "accuracy_test_list2 = []\n",
    "precision_list2 = []\n",
    "recall_list2 = []\n",
    "f1_list2 = []\n",
    "confusion_list2=[]\n",
    "roc_auc_list2=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Optimal Logistic Regression\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8266841281502539\n",
      "The accuracy on test data is: 0.8294533428441735\n",
      "The Precision on test data is : 0.8579481397970687\n",
      "The Recall on test data is : 0.7896238651102464\n",
      "The F1 Score on test data is : 0.8223693097392948\n",
      "The roc_score on test data is : 0.8294507602039366\n",
      "=================================================================\n",
      "\n",
      "\n",
      "1: Optimal Decision Tree\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8279617976810298\n",
      "The accuracy on test data is: 0.8230335257116919\n",
      "The Precision on test data is : 0.8691270194160368\n",
      "The Recall on test data is : 0.7605706874189364\n",
      "The F1 Score on test data is : 0.8112333125821402\n",
      "The roc_score on test data is : 0.8230294754692918\n",
      "=================================================================\n",
      "\n",
      "\n",
      "2: Optimal Random Forest\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8403232503912863\n",
      "The accuracy on test data is: 0.8334738343816873\n",
      "The Precision on test data is : 0.8624189455878207\n",
      "The Recall on test data is : 0.793514915693904\n",
      "The F1 Score on test data is : 0.8265333693596326\n",
      "The roc_score on test data is : 0.833471243348184\n",
      "=================================================================\n",
      "\n",
      "\n",
      "3: Optimal SVM\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.8465518893538186\n",
      "The accuracy on test data is: 0.8380779456585176\n",
      "The Precision on test data is : 0.900938317181972\n",
      "The Recall on test data is : 0.759662775616083\n",
      "The F1 Score on test data is : 0.8242910421504469\n",
      "The roc_score on test data is : 0.8380728610281167\n",
      "=================================================================\n",
      "\n",
      "\n",
      "4: Optimal Gradient Boosting\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.9828472865493341\n",
      "The accuracy on test data is: 0.8644705272031645\n",
      "The Precision on test data is : 0.8951068616422947\n",
      "The Recall on test data is : 0.82568093385214\n",
      "The F1 Score on test data is : 0.8589933882067197\n",
      "The roc_score on test data is : 0.8644680119915609\n",
      "=================================================================\n",
      "\n",
      "\n",
      "[17:28:03] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:576: \n",
      "Parameters: { \"min_samples_leaf\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[17:28:03] WARNING: C:\\Users\\dev-admin\\croot\\xgboost-split_1675120659361\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "5: Optimal XG Boosting\n",
      "Model Training Performance\n",
      "The accuracy on train data is: 0.9965822340051745\n",
      "The accuracy on test data is: 0.8683613254652747\n",
      "The Precision on test data is : 0.9009034443817052\n",
      "The Recall on test data is : 0.8277561608300907\n",
      "The F1 Score on test data is : 0.86278220900365\n",
      "The roc_score on test data is : 0.8683586925276118\n",
      "=================================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(list(models2))):\n",
    "    model = list(models2.values())[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # This is a validation (test) score\n",
    "    accuracy_train,accuracy_test, precision, recall, f1, roc_auc = evaluate_classification_model(model,X_test, X_train, y_test, y_train)\n",
    "\n",
    "    print(f'{i}: {list(models2.keys())[i]}')\n",
    "    model_list2.append(list(models2.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"The accuracy on train data is:\", accuracy_train)\n",
    "    print(\"The accuracy on test data is:\", accuracy_test)\n",
    "    print(\"The Precision on test data is :\", precision)\n",
    "    print(\"The Recall on test data is :\", recall)\n",
    "    print(\"The F1 Score on test data is :\", f1)\n",
    "    print(\"The roc_score on test data is :\", roc_auc)\n",
    "\n",
    "    accuracy_train_list2.append(accuracy_train)\n",
    "    accuracy_test_list2.append(accuracy_test)\n",
    "    precision_list2.append(precision)\n",
    "    recall_list2.append(recall)\n",
    "    f1_list2.append(f1)\n",
    "    roc_auc_list2.append(roc_auc)\n",
    "\n",
    "    print('=' * 65)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df2 = pd.DataFrame({'Classifier':model_list2, \n",
    "                           'Train Accuracy': accuracy_train_list2, \n",
    "                           'Test Accuracy': accuracy_test_list2, \n",
    "                           'Precision': precision_list2, \n",
    "                           'Recall': recall_list2, \n",
    "                           'F1 Score': f1_list2, \n",
    "                           'AUC': roc_auc_list2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Optimal XG Boosting</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.868361</td>\n",
       "      <td>0.900903</td>\n",
       "      <td>0.827756</td>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.868359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optimal Gradient Boosting</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.864471</td>\n",
       "      <td>0.895107</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.858993</td>\n",
       "      <td>0.864468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Optimal SVM</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.759663</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>0.838073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optimal Random Forest</td>\n",
       "      <td>0.840323</td>\n",
       "      <td>0.833474</td>\n",
       "      <td>0.862419</td>\n",
       "      <td>0.793515</td>\n",
       "      <td>0.826533</td>\n",
       "      <td>0.833471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optimal Logistic Regression</td>\n",
       "      <td>0.826684</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>0.857948</td>\n",
       "      <td>0.789624</td>\n",
       "      <td>0.822369</td>\n",
       "      <td>0.829451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optimal Decision Tree</td>\n",
       "      <td>0.827962</td>\n",
       "      <td>0.823034</td>\n",
       "      <td>0.869127</td>\n",
       "      <td>0.760571</td>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.823029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Classifier  Train Accuracy  Test Accuracy  Precision  \\\n",
       "5          Optimal XG Boosting        0.996582       0.868361   0.900903   \n",
       "4    Optimal Gradient Boosting        0.982847       0.864471   0.895107   \n",
       "3                  Optimal SVM        0.846552       0.838078   0.900938   \n",
       "2        Optimal Random Forest        0.840323       0.833474   0.862419   \n",
       "0  Optimal Logistic Regression        0.826684       0.829453   0.857948   \n",
       "1        Optimal Decision Tree        0.827962       0.823034   0.869127   \n",
       "\n",
       "     Recall  F1 Score       AUC  \n",
       "5  0.827756  0.862782  0.868359  \n",
       "4  0.825681  0.858993  0.864468  \n",
       "3  0.759663  0.824291  0.838073  \n",
       "2  0.793515  0.826533  0.833471  \n",
       "0  0.789624  0.822369  0.829451  \n",
       "1  0.760571  0.811233  0.823029  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df2.sort_values(by=['Test Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.867907</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.828534</td>\n",
       "      <td>0.862486</td>\n",
       "      <td>0.867905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG Boosting</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.857402</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.810117</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.857399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.846680</td>\n",
       "      <td>0.845924</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.845921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.759663</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>0.838073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.826524</td>\n",
       "      <td>0.829648</td>\n",
       "      <td>0.858412</td>\n",
       "      <td>0.789494</td>\n",
       "      <td>0.822512</td>\n",
       "      <td>0.829645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.786979</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.786980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Classifier  Train Accuracy  Test Accuracy  Precision    Recall  \\\n",
       "2       Random Forest        0.999553       0.867907   0.899338  0.828534   \n",
       "5         XG Boosting        0.915993       0.857402   0.894714  0.810117   \n",
       "4   Gradient Boosting        0.846680       0.845924   0.882092  0.798573   \n",
       "3                 SVM        0.846552       0.838078   0.900938  0.759663   \n",
       "0  LogisticRegression        0.826524       0.829648   0.858412  0.789494   \n",
       "1        DecisionTree        0.999553       0.786979   0.776805  0.805318   \n",
       "\n",
       "   F1 Score       AUC  \n",
       "2  0.862486  0.867905  \n",
       "5  0.850317  0.857399  \n",
       "4  0.838257  0.845921  \n",
       "3  0.824291  0.838073  \n",
       "0  0.822512  0.829645  \n",
       "1  0.790804  0.786980  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_df.sort_values(by=['Test Accuracy'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comparision_df = pd.concat([compare_df, compare_df2]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comparision_df.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comparision_df.sort_values('Test Accuracy', axis=0, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Optimal XG Boosting</td>\n",
       "      <td>0.996582</td>\n",
       "      <td>0.868361</td>\n",
       "      <td>0.900903</td>\n",
       "      <td>0.827756</td>\n",
       "      <td>0.862782</td>\n",
       "      <td>0.868359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.867907</td>\n",
       "      <td>0.899338</td>\n",
       "      <td>0.828534</td>\n",
       "      <td>0.862486</td>\n",
       "      <td>0.867905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Optimal Gradient Boosting</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.864471</td>\n",
       "      <td>0.895107</td>\n",
       "      <td>0.825681</td>\n",
       "      <td>0.858993</td>\n",
       "      <td>0.864468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XG Boosting</td>\n",
       "      <td>0.915993</td>\n",
       "      <td>0.857402</td>\n",
       "      <td>0.894714</td>\n",
       "      <td>0.810117</td>\n",
       "      <td>0.850317</td>\n",
       "      <td>0.857399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.846680</td>\n",
       "      <td>0.845924</td>\n",
       "      <td>0.882092</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>0.838257</td>\n",
       "      <td>0.845921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.759663</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>0.838073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Optimal SVM</td>\n",
       "      <td>0.846552</td>\n",
       "      <td>0.838078</td>\n",
       "      <td>0.900938</td>\n",
       "      <td>0.759663</td>\n",
       "      <td>0.824291</td>\n",
       "      <td>0.838073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Optimal Random Forest</td>\n",
       "      <td>0.840323</td>\n",
       "      <td>0.833474</td>\n",
       "      <td>0.862419</td>\n",
       "      <td>0.793515</td>\n",
       "      <td>0.826533</td>\n",
       "      <td>0.833471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.826524</td>\n",
       "      <td>0.829648</td>\n",
       "      <td>0.858412</td>\n",
       "      <td>0.789494</td>\n",
       "      <td>0.822512</td>\n",
       "      <td>0.829645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Optimal Logistic Regression</td>\n",
       "      <td>0.826684</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>0.857948</td>\n",
       "      <td>0.789624</td>\n",
       "      <td>0.822369</td>\n",
       "      <td>0.829451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Optimal Decision Tree</td>\n",
       "      <td>0.827962</td>\n",
       "      <td>0.823034</td>\n",
       "      <td>0.869127</td>\n",
       "      <td>0.760571</td>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.823029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.786979</td>\n",
       "      <td>0.776805</td>\n",
       "      <td>0.805318</td>\n",
       "      <td>0.790804</td>\n",
       "      <td>0.786980</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Classifier  Train Accuracy  Test Accuracy  Precision  \\\n",
       "11          Optimal XG Boosting        0.996582       0.868361   0.900903   \n",
       "2                 Random Forest        0.999553       0.867907   0.899338   \n",
       "10    Optimal Gradient Boosting        0.982847       0.864471   0.895107   \n",
       "5                   XG Boosting        0.915993       0.857402   0.894714   \n",
       "4             Gradient Boosting        0.846680       0.845924   0.882092   \n",
       "3                           SVM        0.846552       0.838078   0.900938   \n",
       "9                   Optimal SVM        0.846552       0.838078   0.900938   \n",
       "8         Optimal Random Forest        0.840323       0.833474   0.862419   \n",
       "0            LogisticRegression        0.826524       0.829648   0.858412   \n",
       "6   Optimal Logistic Regression        0.826684       0.829453   0.857948   \n",
       "7         Optimal Decision Tree        0.827962       0.823034   0.869127   \n",
       "1                  DecisionTree        0.999553       0.786979   0.776805   \n",
       "\n",
       "      Recall  F1 Score       AUC  \n",
       "11  0.827756  0.862782  0.868359  \n",
       "2   0.828534  0.862486  0.867905  \n",
       "10  0.825681  0.858993  0.864468  \n",
       "5   0.810117  0.850317  0.857399  \n",
       "4   0.798573  0.838257  0.845921  \n",
       "3   0.759663  0.824291  0.838073  \n",
       "9   0.759663  0.824291  0.838073  \n",
       "8   0.793515  0.826533  0.833471  \n",
       "0   0.789494  0.822512  0.829645  \n",
       "6   0.789624  0.822369  0.829451  \n",
       "7   0.760571  0.811233  0.823029  \n",
       "1   0.805318  0.790804  0.786980  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comparision_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From all baseline model, Random forest classifier shows highest test accuracy and F1 score and AUC.  \n",
    "\n",
    "- Baseline model of decision tree shows huge difference in train and test accuracy which shows overfitting.\n",
    "\n",
    "- After cross validation and hyperparameter tunning, XG Boost shows highest test accuracy score of 86.83% and AUC is 0.8683.\n",
    "\n",
    "- Cross validation and hyperparameter tunning certainly reduces chances of overfitting and also increases performance of model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
